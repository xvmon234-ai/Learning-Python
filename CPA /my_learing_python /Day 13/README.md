# Day 13: 실전 모의고사 3회 (통합형 문제 및 과정 설명 집중)

## 🎯 학습 목표

  - 파이썬, Pandas, 데이터 시각화, 웹 스크래핑 역량을 통합하여 난이도 있는 문제를 해결합니다.
  - 코딩 능력뿐만 아니라 문제 해결 전략, 기술 선택 이유, 인사이트 도출 과정을 논리적으로 설명하는 훈련을 합니다.

### ✔️ 오늘 할 일

  - **모의 문제 해결 (약 2시간)**:
      - 문제 파악 및 해결 전략 수립: 10분
      - 데이터 준비, 전처리, 분석, 시각화 코딩: 1시간
      - 결과 저장 및 코드 정리: 50분
  - **자기 분석 및 설명 연습 (약 2시간)**:
      - 해결 과정을 구체적으로 글로 작성하고, 각 단계에서 왜 그런 선택을 했는지 논리적으로 설명합니다.
      - 이 과정을 AI에게 제출하고 '면접관' 역할을 부여하여 피드백을 받는 훈련을 진행합니다.

-----

### 📝 실습 문제 및 요구사항

#### 데이터 준비

아래 코드를 실행하여 실습에 필요한 `sales_data.csv` 파일을 생성하세요.

```python
import pandas as pd
import numpy as np

# 대규모 판매 데이터 생성 (CSV)
data = {
    'sale_id': range(1, 2001),
    'product_id': np.random.choice(range(101, 151), 2000),
    'sale_date': pd.to_datetime(pd.date_range(start='2023-01-01', periods=2000, freq='H')),
    'quantity': np.random.randint(1, 20, 2000),
    'price': np.random.randint(1000, 50000, 2000)
}
df_sales = pd.DataFrame(data)

# 결측치, 중복값, 이상치 추가
df_sales.loc[50:100, 'price'] = np.nan
df_sales.loc[1000:1050, 'quantity'] = -1
df_sales.loc[1500:1510] = df_sales.loc[0:10].values

df_sales.to_csv('sales_data.csv', index=False)

print("sales_data.csv 파일이 생성되었습니다.")
```

#### 모의 문제 (통합형)

주어진 `sales_data.csv`를 활용하여 아래의 모든 요구사항을 수행하시오.

1.  **데이터 불러오기 및 전처리:**

      - `sales_data.csv` 파일을 불러와 DataFrame으로 만드시오.
      - 데이터의 초기 구조를 파악하고, 결측치와 중복값을 효율적으로 처리하시오.
      - `quantity`가 음수인 이상치를 1로 대체하시오.

2.  **분석 및 시각화:**

      - 특정 기간(예: **2023년 1월 \~ 3월**) 동안의 **일별 평균 판매량**을 계산하고, 이를 **꺾은선 그래프**로 시각화하여 추세를 분석하시오.
      - 가장 높은 판매량을 기록한 **상위 10개 상품**(`product_id`)을 찾고, 각 상품의 **총 판매액**을 **막대 그래프**로 시각화하시오. (총 판매액 = `quantity` \* `price`)

3.  **데이터 저장:**

      - 최종 분석 결과(상위 10개 상품의 총 판매액)를 SQLite 데이터베이스 파일(예: `sales_summary.db`)의 테이블에 저장하시오.

-----

### ✅ 결과물

#### ✍️ 문제 해결 과정

[**전체 코딩 보러가기**]

#### 📊 시각화 결과

  - **2023년 1\~3월 일별 평균 판매량:**
    
  - **판매량 상위 10개 상품의 총 판매액:**

-----

### 🧠 자기 분석 및 설명 연습 (면접관 역할 부여)


**[문제 해결 전략]** 이 문제를 어떤 순서로 접근했나요? 각 단계에서 어떤 목표를 세웠는지 설명해 주세요.

> **답변:** "이 문제는 데이터 전처리, 분석, 시각화, 그리고 결과 저장이라는 네 단계로 구성되어 있다고 판단했습니다.
>
> 1.  **전처리 단계:** `read_csv`로 데이터를 불러온 후 `info()`로 초기 상태를 파악하는 것이 첫 번째 목표였습니다. `price` 열의 결측치, `quantity` 열의 음수값, 그리고 중복된 행과 같은 데이터 품질 문제를 해결하여 분석에 적합한 상태로 만드는 것을 목표로 삼았습니다.
> 2.  **분석 단계:** `sale_date` 열을 `datetime` 타입으로 변환하고, 이를 활용해 특정 기간의 일별 평균 판매량을 계산했습니다. 또한, `quantity`와 `price`를 곱해 총 판매액을 구하고, 이를 기준으로 상위 10개 상품을 찾는 것이 목표였습니다.
> 3.  **시각화 단계:** 분석 결과를 바탕으로 데이터의 추세와 인사이트를 시각적으로 보여주는 것이 목표였습니다. 시간 흐름에 따른 변화는 **꺾은선 그래프**로, 항목별 비교는 **막대 그래프**로 표현하기로 계획했습니다.
> 4.  **저장 단계:** 최종적으로 도출된 핵심 분석 결과(상위 10개 상품)를 영구적으로 보관하고 다른 시스템에서 쉽게 활용할 수 있도록 **SQLite 데이터베이스**에 저장하는 것을 목표로 삼았습니다."

---

**[기술 선택 이유]** 데이터 전처리 시 결측치와 중복값을 처리하기 위해 사용한 Pandas 메서드는 무엇이고, 왜 그 방법을 선택했는지 설명해 주세요.

> **답변:** "`price` 열의 결측치를 처리하기 위해 `fillna()`와 `.median()`을 사용했습니다. 판매 데이터의 가격은 극단적인 값(이상치)이 존재할 수 있으므로, 평균값보다 **중앙값**이 데이터의 전체적인 분포를 더 잘 대표한다고 판단했기 때문입니다. `quantity` 열의 음수값은 논리적으로 불가능한 이상치이므로, `.loc`을 사용하여 조건에 맞는 행의 값을 최소값인 1로 일괄 대체했습니다. 중복된 행은 `drop_duplicates()` 메서드를 사용하여 깔끔하게 제거했습니다. 이 모든 작업은 Pandas의 강력한 메서드들을 활용하여 한두 줄의 코드로 효율적으로 처리할 수 있었습니다."

---

**[예상치 못한 문제]** 코딩 과정에서 어떤 어려움이나 예상치 못한 에러가 발생했나요? 그 에러를 어떻게 디버깅하고 해결했는지 구체적으로 설명해 주세요.

> **답변:** "처음에 `df = pd.read_csv('sales_data.csv')` 코드를 실행했을 때, 파일이 존재하지 않아 `FileNotFoundError`가 발생했습니다. 이 문제를 해결하기 위해 `try-except` 구문을 사용했습니다. `try` 블록에서 파일을 읽고, `except` 블록에서 `FileNotFoundError`가 발생하면, 제공된 코드로 파일을 생성하고 다시 읽어오도록 로직을 추가했습니다. 이렇게 함으로써 코드가 외부 파일의 존재 여부에 의존하지 않고 스스로 실행될 수 있는 **견고한(Robust) 코드**가 되었습니다."

---

**[인사이트 도출]** 시각화된 두 그래프에서 각각 어떤 인사이트를 발견했나요? 이 인사이트를 바탕으로 실제 비즈니스에 어떤 제언을 할 수 있을까요?

> **답변:**
>
> - **일별 평균 판매량 추이 그래프:** 1월 초에는 판매량이 다소 낮다가 중순에 급격히 상승하고, 2월과 3월에는 비교적 안정적인 추세를 유지하는 것을 볼 수 있습니다. 이 급격한 판매량 증가는 신년 프로모션이나 특정 이벤트의 영향일 가능성이 높습니다. **제언:** 다음 해에도 같은 시기에 마케팅 활동을 집중하고, 판매량이 감소하는 시기에는 새로운 전략을 도입해 매출을 유지해야 합니다.
>
> - **상위 10개 상품의 총 판매액 그래프:** 특정 소수의 상품(`product_id` 101, 107 등)이 전체 매출의 상당 부분을 차지하고 있음을 알 수 있습니다. **제언:** 이 핵심 상품들(Cash Cow)에 대한 재고 관리를 철저히 하고, 이 상품들을 활용한 연관 상품 추천이나 번들 판매 전략을 세워 전체적인 매출 증대를 꾀할 수 있습니다.
