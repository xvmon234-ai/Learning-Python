---

# **Day 14: Pandas 심화 및 데이터 분석 통합 최종 보고서**

## 💡 **개요**

본 문서는 Day 1부터 Day 13까지 진행된 **Pandas 기반의 데이터 분석 및 처리** 학습 내용을 종합한 최종 보고서입니다. 데이터 분석의 A부터 Z까지, 즉 데이터 불러오기, 전처리, 조작, 시각화, 웹 스크래핑, 그리고 실제 비즈니스 문제 해결까지의 모든 과정을 총망라합니다. 이를 통해 삼일회계법인 Digital 전형 지원을 위한 GitHub 포트폴리오의 학습 증빙 자료로 활용하고자 합니다.

---

## 🚀 **학습 내용 및 성과 요약**

### **Part 1: Pandas 기초 및 데이터 정제 (Day 1 - Day 5)**

* **Day 1: Pandas 기본기 - 데이터 생성 및 선택**
    `Series`, `DataFrame`의 개념을 이해하고, 데이터를 생성하는 다양한 방법을 학습했습니다. 특히 `.head()`, `.tail()`, `.info()`를 활용하여 데이터의 초기 구조와 속성을 빠르게 파악하는 연습을 통해 데이터 분석의 첫 단추를 제대로 끼웠습니다.

* **Day 2: Pandas 기본기 - 인덱싱 및 필터링**
    데이터프레임의 특정 데이터를 선택하는 핵심 기술인 인덱싱(`loc`, `iloc`)을 숙달하고, 조건식을 활용한 불리언 필터링 방법을 배웠습니다. 대규모 데이터셋에서 원하는 정보를 정확하게 추출하는 능력을 길렀습니다.

* **Day 3: 데이터 구조 및 조작 - 컬럼 조작 및 정렬**
    기존 데이터프레임에서 새로운 컬럼을 생성하거나, 데이터프레임의 행과 열을 원하는 기준으로 정렬하는 방법을 익혔습니다. 또한, `astype()`을 사용해 컬럼의 데이터 타입을 변환하며 데이터 전처리 역량을 강화했습니다.

* **Day 4: 데이터 구조 및 조작 - 조건부 데이터 처리**
    하나 이상의 조건을 조합하여 복잡한 데이터 필터링을 수행하는 방법을 배웠습니다. `df.loc[조건, '컬럼'] = 값` 형태의 문법을 사용해 특정 조건에 맞는 데이터만 선택적으로 변경하는 기술을 익혔습니다.

* **Day 5: 결측치 및 중복값 처리**
    `isnull()`, `dropna()`, `fillna()`를 활용해 결측치를 식별하고 처리하는 방법을 배웠습니다. 또한, `duplicated()`, `drop_duplicates()`를 사용해 중복 데이터를 효율적으로 관리하는 방법을 익혔습니다.

### **Part 2: 데이터 조작 및 분석 심화 (Day 6 - Day 8)**

* **Day 6: 그룹화 및 집계**: `groupby()`와 `agg()`를 활용해 데이터를 특정 기준으로 그룹화하고 요약 통계를 계산하는 방법을 배웠습니다. 특히 `transform()`, `filter()` 등 고급 기법을 통해 그룹별 연산을 원본 데이터에 적용하며 실무적 활용 능력을 함양했습니다.
* **Day 7: 데이터 병합 및 결합**: `pd.merge()`를 통해 `inner`, `left`, `right`, `outer` 조인을 이해하고, `pd.concat()`으로 데이터를 물리적으로 연결하는 방법을 숙달했습니다. 다양한 데이터 소스를 통합하는 데 필수적인 `pivot_table()` 사용법도 익혔습니다.
* **Day 8: 실전 모의고사 1회**: Pandas의 여러 기능을 종합하여 데이터 불러오기, 전처리, 집계, 저장에 이르는 데이터 분석의 전체 워크플로우를 직접 경험하며 실전 감각을 익혔습니다. 이 과정에서 문제 해결 전략을 스스로 수립하는 훈련을 했습니다.

### **Part 3: 고급 기법 및 시각화/웹 스크래핑 (Day 9 - Day 13)**

* **Day 9: 데이터 시각화 기초**: `Matplotlib`과 `Seaborn`을 활용해 꺾은선 그래프, 막대 그래프, 산점도, 히트맵 등 다양한 차트를 그려 데이터의 패턴을 시각적으로 파악하는 능력을 확보했습니다. 분석 결과를 효과적으로 전달하는 커뮤니케이션 도구로서의 시각화의 중요성을 배웠습니다.
* **Day 10: 고급 Pandas 기법**: `apply()`, `map()`, `replace()` 등 데이터 변환을 위한 고급 메서드와 범주형 데이터(`category`) 처리, 날짜/시간 데이터(`datetime`) 처리 방법을 익혀 데이터 전처리 역량을 심화했습니다. 이를 통해 대규모 데이터셋을 효율적으로 다루는 방법을 익혔습니다.
* **Day 11: 실전 모의고사 2회**: 데이터 병합, 결측치/이상치 처리, 시각화, 인사이트 도출 등 복합적인 과제를 해결하며 실무 프로젝트 수행 능력을 강화했습니다. 다양한 포맷의 파일(`CSV`, `Excel`)을 다루는 실전 경험을 쌓았습니다.
* **Day 12: 웹 스크래핑 기초**: `Requests`와 `Beautiful Soup` 라이브러리를 사용해 웹페이지의 HTML을 파싱하고, 정적 데이터뿐만 아니라 `iframe` 내의 복잡한 데이터까지 추출하는 기술을 습득했습니다. 비정형 웹 데이터를 분석에 활용하는 기반을 마련했습니다.
* **Day 13: 실전 모의고사 3회**: Pandas, 시각화, 데이터베이스 저장 등 모든 학습 내용을 통합하여 고난도 문제를 해결했습니다. 코딩뿐만 아니라, 문제 해결 전략과 인사이트를 논리적으로 설명하는 훈련을 통해 분석가로서의 커뮤니케이션 능력을 강화했습니다.

---

## 📈 **총평 및 자기성찰**

지난 13일간의 학습을 통해 Pandas와 Python 기반의 데이터 처리 능력은 물론, 문제를 구조화하고 해결하는 논리적 사고력을 크게 향상시킬 수 있었습니다. 특히, 단순한 코드 작성을 넘어 **왜** 특정 방법을 선택했는지, **어떤** 인사이트를 도출했는지 설명하는 훈련은 데이터 분석가에게 가장 중요한 `문제 해결`과 `커뮤니케이션` 역량을 동시에 길러주었습니다.

본 학습을 통해 얻은 지식과 경험은 향후 삼일회계법인의 Digital 전문가로서 데이터를 다루고 분석하는 데 있어 견고한 기반이 될 것입니다.
