네, 요청하신 대로 이전에 제시해 드린 두 가지 내용을 하나로 합쳐 GitHub `README.md` 파일에 업로드하기 적합한 방식으로 재구성해 드립니다.

이 문서는 Day 5 학습 내용을 [주제, 이론(중요도 표시), 암기할 사항(중요도 표시), 학습 과정에서 얻은 피드백 및 해결 경험(❗ 표시)]으로 정리하며, 삼일회계법인 Digital 전형 지원을 위한 학습 증빙 자료로 활용될 수 있습니다.

---

# 📈 **[Day 5] Pandas 데이터 정제: 결측치 및 중복값 처리 학습 보고서**

### **개요**

본 보고서는 삼일회계법인 Digital 전형 지원을 위한 GitHub 학습 증빙 자료의 일환으로, Pandas 라이브러리를 활용한 데이터 정제 과정 중 **결측치(Missing Values)** 및 **중복값(Duplicate Values)** 처리 학습 내용을 정리합니다. 데이터 분석 및 모델링 전 필수적인 전처리 단계를 이해하고 실제 데이터를 다루는 역량을 보여주는 데 중점을 둡니다.

---

### **학습 목표**

* 데이터 내에 존재하는 결측값(NaN, None) 및 중복값을 효율적으로 식별하고 처리하는 기법 숙달.
* 정확하고 신뢰할 수 있는 데이터 분석 결과를 도출하기 위한 견고한 데이터 전처리 기반 마련.
* Pandas `isnull()`, `dropna()`, `fillna()`, `duplicated()`, `drop_duplicates()` 등 핵심 메서드의 활용 능력 함양.

---

### **주요 학습 내용 및 성과**

#### **1. 결측치(Missing Values)의 개념 및 확인**

**이론**
* 🌟🌟🌟 **결측치(NaN)의 개념 및 중요성**: 데이터 수집 오류, 정보 부재 등으로 인해 발생하는 누락된 값(`np.nan`, `None`, `NaT` 등)을 의미합니다. 통계 왜곡 및 모델 학습 방해를 야기하므로 적절한 처리가 필수적입니다.
* 🌟🌟🌟 **`df.isnull()` / `df.isna()`**: DataFrame 내의 모든 요소에 대해 결측치 여부를 `True`/`False`로 반환하는 메서드입니다. (두 메서드는 동일 기능)
* 🌟🌟🌟 **`df.isnull().sum()`**: 각 컬럼별 결측치의 개수를 Series 형태로 반환하여 결측치 현황을 빠르게 파악할 수 있는 **가장 유용한 방법**입니다.
* 🌟 **`df.isnull().sum().sum()`**: 데이터프레임 전체의 총 결측치 개수를 반환합니다.

**암기할 사항**
* 🌟🌟🌟 결측치 확인의 **가장 기본이자 필수**: **`df.isnull().sum()`**
* 🌟 `isnull()`은 불리언 값(True/False)을 반환하며, `.sum()`과 결합하여 개수를 세거나, **불리언 인덱싱**을 통해 결측치가 있는 행을 필터링할 수 있습니다.

**❗ 학습 과정 피드백**
* **Numpy import 이유**: Pandas는 결측치를 표현할 때 `np.nan`을 사용하므로, Pandas와 함께 Numpy를 import하는 것이 일반적입니다.
* **불리언 인덱싱 오류 개선**: `df[df["col1"].isnull().sum()]`와 같이 `.sum()`을 포함하면 오류가 발생합니다. `df[df["col1"].isnull()]`처럼 `isnull()`이 반환하는 **불리언 Series 자체**를 사용해야 올바른 필터링이 가능합니다.

---

#### **2. 결측치(Missing Values) 처리: 삭제**

**이론**
* 🌟🌟🌟 **`df.dropna()`**: 결측치가 포함된 행 또는 열을 삭제하는 메서드입니다.
    * `axis=0` (기본값): 행(row) 삭제. `axis=1`: 열(column) 삭제.
    * `how='any'` (기본값): 해당 행/열에 하나라도 결측치가 있으면 삭제. `how='all'`: 해당 행/열의 모든 값이 결측치일 때만 삭제.
    * `subset`: 특정 컬럼(들)을 기준으로 결측치 여부를 확인하여 삭제 범위를 제한합니다.

**암기할 사항**
* 🌟 **`dropna()`의 `axis`, `how`, `subset`, `inplace` 옵션의 의미와 활용법**을 정확히 이해해야 합니다.
* 🌟 `dropna()`는 원본을 변경하지 않으므로, 결과를 새로운 변수에 할당하거나 **`inplace=True`**를 사용해야 합니다.

**❗ 학습 과정 피드백**
* **`dropna()`와 `subset` 사용 시 `axis` 관계**: `subset` 매개변수를 지정하면 `dropna()`는 기본적으로 행(row)을 삭제하는 `axis=0`으로 동작합니다. 따라서 `subset`을 사용할 때는 `axis=0`을 명시적으로 지정하지 않아도 됩니다.

---

#### **3. 결측치(Missing Values) 처리: 대체**

**이론**
* 🌟🌟🌟 **`df.fillna()`**: 결측치를 특정 값으로 대체하는 가장 일반적이고 강력한 메서드입니다.
    * `value`: 상수(예: `0`, `'Unknown'`), 통계량(예: `df['col'].mean()`, `df['col'].median()`), 또는 다른 컬럼의 값 등으로 채울 수 있습니다.
    * `method`: `'ffill'` (forward fill, 이전 값으로 채우기) 또는 `'bfill'` (backward fill, 다음 값으로 채우기)과 같이 논리적으로 결측치를 채울 때 사용합니다.

**암기할 사항**
* 🌟🌟 **`fillna()`는 결측치를 처리하는 가장 일반적이고 강력한 방법**입니다.
* 🌟 결측치를 채울 값은 데이터의 특성과 분석 목표에 따라 **신중하게 선택**해야 합니다 (평균/중앙값, 최빈값, `ffill`/`bfill` 등).
* 🌟 **`ffill`**은 바로 이전(위쪽) 유효한 값으로, **`bfill`**은 바로 다음(아래쪽) 유효한 값으로 결측치를 채웁니다.

**❗ 학습 과정 피드백**
* **특정 컬럼 평균 대체 시 대상 컬럼 일치**: `df_sample_na['col1']`의 결측치를 채울 때는 `df_sample_na['col1'].mean()`처럼 해당 컬럼의 평균을 사용해야 합니다. 다른 컬럼의 평균을 사용하면 데이터의 통계적 특성이 왜곡될 수 있습니다.
* **`fillna()` 결과의 적용**: `fillna()`는 새로운 Series/DataFrame을 반환하므로, `df['col'] = df['col'].fillna(value)`와 같이 원본 컬럼에 재할당하거나 새로운 변수에 저장해야 변경 사항이 반영됩니다.

---

#### **4. 중복값(Duplicate Values)의 개념 및 처리**

**이론**
* 🌟🌟 **중복값의 개념 및 중요성**: 데이터셋 내에 완전히 동일하거나 특정 기준으로 중복되는 행이 존재하는 경우를 의미합니다. 이는 분석의 왜곡을 초래하므로 반드시 처리해야 합니다.
* 🌟🌟 **`df.duplicated()`**: 각 행이 중복인지 여부를 `True`/`False`로 반환하는 Series를 생성합니다.
    * `subset`: 특정 컬럼(들)을 기준으로 중복 여부를 확인합니다.
    * `keep`: `'first'` (기본값, 첫 번째 중복 유지), `'last'` (마지막 중복 유지), `False` (모든 중복을 `True`로 표시하거나, `drop_duplicates` 시 모두 제거) 옵션이 있습니다.
* 🌟🌟 **`df.drop_duplicates()`**: 중복된 행을 실제로 제거하여 유일한 행만 남기는 메서드입니다. `subset`, `keep` 매개변수는 `duplicated()`와 동일하게 작동합니다.

**암기할 사항**
* 🌟 **`duplicated()`는 중복 여부만 확인**하고, **`drop_duplicates()`는 실제로 중복된 행을 제거**합니다.
* 🌟 `subset`과 `keep` 옵션을 잘 활용하여 원하는 중복 처리 방식을 구현해야 합니다.
* 🌟 **`sort_values()`와 `drop_duplicates()`를 함께 사용**하면 특정 기준(예: 가장 큰 값)을 가진 중복 행만 남기는 고급 기법을 효과적으로 구현할 수 있습니다.

**❗ 학습 과정 피드백**
* **`drop_duplicates()`의 `subset` 활용**: `subset`에 특정 컬럼 리스트를 전달하여 해당 컬럼들의 조합이 중복될 경우에만 중복으로 간주하고 제거할 수 있습니다. 이는 복합적인 중복 기준을 설정할 때 유용합니다.

---

### **💡 학습 과정에서 얻은 인사이트 및 해결 경험 (종합)**

Day 5 학습은 데이터 분석의 '기본기'를 다지는 중요한 과정이었습니다. 특히 다음과 같은 점들을 깊이 있게 이해하고 숙련하는 기회가 되었습니다.

* **Pandas 메서드의 유연성**: `isnull()`, `dropna()`, `fillna()`, `duplicated()`, `drop_duplicates()` 등 Pandas의 다양한 메서드들이 `axis`, `how`, `subset`, `method`, `keep` 등의 풍부한 매개변수를 통해 사용자의 다양한 데이터 처리 요구사항을 충족시킬 수 있음을 체감했습니다. 각 매개변수가 데이터 처리 결과에 미치는 영향을 명확히 이해하게 되었습니다.
* **원본 데이터 보존과 변경**: `inplace=True`의 중요성과 함께, 메서드 체이닝(`df.sort_values().drop_duplicates()`) 또는 명시적 재할당(`df['col'] = df['col'].fillna(value)`)을 통해 원본 데이터를 효율적으로 관리하는 방법을 익혔습니다.
* **문제 해결을 위한 조합**: 단순히 메서드를 아는 것을 넘어, `sort_values()`와 `drop_duplicates()`를 조합하여 '가장 큰 Amount를 가진 중복 행만 남기는' 복합적인 문제처럼, 여러 기능을 유기적으로 연결하여 실제 데이터 분석 과제를 해결하는 사고력을 길렀습니다.
* **정확한 이해의 중요성**: `isnull().sum()`과 `isnull()`의 차이, 특정 컬럼의 평균으로 대체 시 해당 컬럼의 평균을 사용해야 하는 이유 등, 작은 디테일들이 코드의 정확성과 결과의 신뢰성에 큰 영향을 미침을 인지했습니다. 이는 향후 데이터 전처리 시 발생할 수 있는 잠재적 오류를 예방하는 데 큰 도움이 될 것입니다.

---

### **✅ 결론**

Day 5 학습을 통해 데이터 전처리의 핵심 요소인 결측치와 중복값을 효과적으로 식별하고 처리하는 Pandas의 다양한 메서드들을 숙지했습니다. 특히 실전에서 유용한 기법들을 체득함으로써, 데이터 분석의 신뢰성을 높이는 데 필수적인 역량을 강화했습니다. 이 학습 경험은 향후 삼일회계법인 Digital 전형에서 요구하는 데이터 처리 역량의 중요한 기반이 될 것입니다.

---
