# 삼일회계법인 디지털 전형 대비 개인 학습 기록

## 🚀 프로젝트/학습 개요

이 GitHub 저장소는 **삼일회계법인 디지털 전형 합격**을 목표로 진행한 **데이터 분석 및 프로그래밍 학습 여정**을 기록합니다. 특히, Python 기본기부터 Pandas를 활용한 데이터 처리 및 시각화, 나아가 웹 스크래핑을 통한 데이터 수집 능력까지 **AI(Gemini)와 협업**하여 초고속으로 습득한 내용을 담고 있습니다.

또한, [**"ESG 공시 트렌드 분석: KB금융지주 & SK이노베이션" 프로젝트**](https://www.google.com/search?q=%EB%A7%81%ED%81%AC_%EC%97%AC%EA%B8%B0%EC%97%90_%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8_README_%EC%A3%BC%EC%86%8C_%EC%82%BD%EC%9E%85)는 본 학습 과정에서 체득한 역량을 실제 데이터 분석에 적용하여 완성한 결과물입니다. 이 프로젝트는 금융과 제조/에너지라는 상반된 산업 특성을 가진 두 기업의 ESG 데이터를 분석하며, 데이터 기반의 비즈니스 인사이트 도출 역량을 선보이고자 했습니다.

이 두 기업을 선정한 주요 이유는 삼일회계법인과의 **잠재적 이해관계** 및 **상반된 산업 특성**을 고려했기 때문입니다. KB금융지주와 SK이노베이션은 모두 대규모 상장법인이자 외부감사 대상으로, 삼일회계법인이 감사 및 자문 서비스를 제공할 가능성이 높은 기업들입니다. 또한, 금융업과 제조/에너지업은 ESG 경영에서 중요하게 다루는 요소와 공시 트렌드에 극명한 차이를 보여, 산업별 ESG 공시의 특성과 차별화된 전략을 명확하게 도출하는 데 의미 있는 분석 대상이 됩니다.

주요 목표는 핵심 ESG(환경, 사회, 지배구조) 키워드 언급 빈도와 온실가스(GHG) 배출량의 연도별 트렌드를 파악하고 시각화하여, 각 기업의 ESG 경영 전략 및 공시 관행에 대한 의미 있는 인사이트를 도출하는 것이었습니다. 이 분석은 기업의 비재무적 성과를 이해하는 데 있어 데이터 기반 접근 방식의 중요성을 강조합니다.

본 저장소의 학습 기록은 삼일회계법인의 디지털 인재상에 부합하는 **데이터 활용 능력, 문제 해결 역량, 그리고 빠른 학습 속도**를 증명하는 자료가 될 것입니다.

-----

## 💡 학습 커리큘럼 소개

다음의 커리큘럼은 **AI(Gemini)를 활용**하여 삼일회계법인 디지털 전형에 최적화된 역량을 기르기 위해 설계된 초고속 학습 로드맵입니다. AI의 도움으로 얻은 면접 진행 방식과 예상 질문에 맞춰 파이썬 기본기, 데이터 분석 역량, 그리고 데이터 수집 능력을 강화하는 데 초점을 맞추었습니다.

-----

### 🚀 학습 가이드

  * **매일 복습 및 손 코딩:** 전날 학습한 내용을 직접 타이핑하며 익숙해지는 연습을 합니다. 자동 완성 기능에 의존하기보다 핵심 코드를 직접 작성하며 코드 구조를 머릿속에 각인하세요.
  * **오답 노트/블로그 활용:** 막혔던 문제, AI로 해결한 내용, 새롭게 알게 된 함수 등을 정리하고 복습하여 면접 시 \*\*'과정 설명'\*\*에 대비합니다.
  * **시간 관리:** 각 연습 세션에 타이머를 설정하여 실제 면접 환경에 익숙해지는 훈련을 합니다. 특히 코딩 시간은 **20분 내외로 제한**하는 연습을 매일 꾸준히 해야 합니다.
  * **AI (Gemini/ChatGPT) 활용:** 막힐 때마다 적극적으로 질문하고, 개념을 확실히 이해하며, 자신의 코드를 최적화하는 핵심 파트너로 활용하세요. AI는 이 초고속 커리큘럼의 핵심입니다.

-----

### 🗓️ Day-by-Day 학습 로드맵

각 Day별 학습 내용은 해당 일자의 폴더 또는 파일에 상세히 기록되어 있습니다.

#### **Day 1: 파이썬 기본기 (변수, 자료형 중심)**

  * **목표:** 파이썬 핵심 자료형인 \*\*리스트(List)\*\*와 \*\*딕셔너리(Dictionary)\*\*의 주요 메서드 및 특징을 완벽히 이해합니다.
  * **주요 학습 내용:** Python의 기본 자료형(정수, 실수, 문자열, 불린)을 복습하고 변수에 할당하는 방법을 익힙니다. 이어서, **리스트**의 생성, 접근, 슬라이싱, `append`, `remove`와 같은 주요 메서드를 숙달합니다. **딕셔너리**는 `키(key)`를 통해 값을 빠르게 접근하는 방법을 중심으로 학습합니다.

#### **Day 2: 파이썬 기본기 (조건문, 반복문, 함수)**

  * **목표:** 제어문과 함수를 사용하여 기본적인 로직 구현 능력 확보.
  * **주요 학습 내용:** `if`, `elif`, `else` 조건문과 `and`, `or`, `not` 논리 연산자를 활용하는 방법을 익힙니다. 데이터를 순회하며 코드를 실행하는 `for` 반복문과 조건이 `True`인 동안 반복하는 `while` 반복문을 능숙하게 사용하고, 함수를 정의(`def`)하고 매개변수와 반환값을 다루는 방법을 학습합니다.

#### **Day 3: Pandas 기초 (데이터 로딩 및 탐색)**

  * **목표:** Pandas **DataFrame**의 개념을 이해하고, CSV/Excel 데이터를 불러와 기본 정보를 확인합니다.
  * **주요 학습 내용:** Pandas `Series`와 `DataFrame`의 개념을 이해하고, `pd.read_csv()`와 `pd.read_excel()` 함수를 사용해 다양한 형식의 파일을 불러옵니다. `df.head()`, `df.info()`, `df.describe()` 등을 통해 데이터의 형태, 자료형, 통계 정보 등을 빠르게 파악하는 방법을 익힙니다.

#### **Day 4: Pandas 데이터 선택 및 필터링**

  * **목표:** **`loc`**, \*\*`iloc`\*\*를 활용한 데이터 선택 및 복합 조건 필터링 숙달.
  * **주요 학습 내용:** 라벨(이름)을 기반으로 데이터를 선택하는 \*\*`df.loc`\*\*와 정수 위치를 기반으로 선택하는 선택하는 \*\*`df.iloc`\*\*의 사용법을 완벽히 익힙니다. 여러 조건을 결합하여 원하는 데이터를 추출하는 불리언 인덱싱과 `isin()`, `str.contains()` 같은 유용한 함수들을 활용하는 연습을 합니다.

#### **Day 5: Pandas 데이터 정제**

  * **목표:** 데이터 분석의 핵심인 결측치와 중복값을 효율적으로 처리하는 방법 숙달.
  * **주요 학습 내용:** `df.isnull().sum()`을 통해 결측치의 위치와 개수를 확인하고, `df.dropna()`로 행/열을 삭제하거나 `df.fillna()`로 특정 값, 평균, 중앙값 등으로 결측치를 대체하는 방법을 학습합니다. `df.duplicated()`와 `df.drop_duplicates()`를 사용해 중복값을 제거하는 방법도 익힙니다.

#### **Day 6: Pandas 데이터 조작 (정렬, 그룹화, 집계)**

  * **목표:** 데이터 **정렬**, **그룹화**, **집계** 기능을 자유자재로 활용.
  * **주요 학습 내용:** `df.sort_values()`를 이용해 단일/다중 컬럼 기준으로 데이터를 정렬합니다. `df.groupby()`를 사용해 데이터를 그룹별로 묶고 `sum()`, `mean()`, `count()` 등의 집계 함수를 적용하며, `df.agg()`를 이용해 한 번에 여러 집계 함수를 적용하는 방법도 익힙니다.

#### **Day 7: Pandas 데이터 병합 및 결합**

  * **목표:** 여러 **DataFrame**을 병합(**`merge`**)하고 연결(**`concat`**)하는 방법 숙달.
  * **주요 학습 내용:** `pd.merge()`의 `inner`, `left`, `right`, `outer` 조인 방식을 심도 있게 연습하여 여러 데이터를 하나로 합치는 방법을 학습합니다. `pd.concat()`을 사용해 단순히 DataFrame을 행 또는 열 방향으로 연결하는 방법도 익힙니다.

#### **Day 8: 실전 모의고사 1회 (데이터 처리 및 정제)**

  * **목표:** 지금까지 학습한 Pandas 기능을 종합하여 실제 데이터 처리 문제 해결 능력 강화.
  * **핵심:** 20분 내 코딩 후 **문제 해결 과정을 말로 설명하는 연습**에 집중합니다. 자신이 어떤 함수를 왜 사용했는지, 어떤 순서로 문제를 해결했는지 설명하는 스크립트를 만들어 보세요.

#### **Day 9: 데이터 시각화 기초**

  * **목표:** **Matplotlib**와 **Seaborn**을 활용한 기본적인 시각화로 인사이트 도출.
  * **주요 학습 내용:** `plt.plot()`, `plt.scatter()`, `sns.barplot()` 등 기본적인 차트를 그리는 법을 배우고, 제목, 축 레이블, 범례 등을 추가하여 차트를 꾸미는 방법을 익힙니다.

#### **Day 10: 고급 Pandas 기법 및 데이터 변환**

  * **목표:** 데이터 조작 및 변환을 위한 고급 Pandas 기법 숙달.
  * **주요 학습 내용:** DataFrame의 행/열에 사용자 정의 함수를 적용하는 **`apply()`와 `lambda` 함수**를 학습합니다. `map()`과 `replace()`를 이용해 특정 값을 교체하고, 날짜/시간 데이터(`pd.to_datetime()`)를 효율적으로 다루는 방법을 익힙니다.

#### **Day 11: 실전 모의고사 2회 (고급 데이터 처리 및 분석)**

  * **목표:** 복잡한 데이터 처리 및 분석 문제 해결 능력 강화, 시각화 포함.
  * **핵심:** 여러 데이터프레임을 병합하여 인사이트를 도출하고 시각화하는 통합 문제 해결 과정 연습. Day 8과 동일하게 해결 과정을 말로 설명하는 연습을 필수적으로 진행합니다.

#### **Day 12: 웹 스크래핑 기초 (Beautiful Soup & Requests)**

  * **목표:** 웹에서 데이터를 수집하여 데이터 분석에 활용하는 역량 확보.
  * **주요 학습 내용:** 웹페이지의 HTML/CSS 구조를 이해하고, `requests` 라이브러리를 사용해 웹페이지의 데이터를 가져옵니다. `Beautiful Soup` 라이브러리를 활용해 가져온 데이터에서 원하는 정보(태그, 클래스 등)를 효율적으로 추출하는 방법을 학습합니다.
  * **실전 연습:** 간단한 웹사이트(예: 블로그 글 목록, 상품 이름)에서 제목과 URL을 스크래핑하는 실습을 진행합니다.

#### **Day 13: 실전 모의고사 3회 (통합형 문제 및 과정 설명 집중)**

  * **목표:** 파이썬, Pandas, 시각화, **웹 스크래핑** 역량을 통합하여 난이도 있는 문제를 해결하고, 특히 **과정 설명 연습에 집중**.
  * **핵심:** AI에게 **'면접관' 역할을 부여**하고, 자신의 해결 과정 설명에 대한 피드백을 받는 훈련을 합니다. 코딩 자체보다 문제 해결 전략과 설명 능력에 더 많은 시간을 할애합니다.

#### **Day 14: 최종 복습 및 면접 질문 대비**

  * **목표:** 전체 학습 내용 빠르게 복습, 면접 시 예상 질문 답변 연습, 마인드셋 정리.
  * **주요 활동:** 그동안 풀었던 모의고사 문제와 정리해둔 핵심 개념, AI에게 질문했던 내용들을 다시 한번 확인하며 빠르게 복습합니다. 면접에서 나올 수 있는 질문들에 대한 답변을 스스로 말해보거나 기록해 보세요.

-----
