# **Card Fraud Detection Project: 이상 거래 탐지 모델 개발**

### **1. 프로젝트 개요**

이 프로젝트는 신용카드 거래 데이터를 활용해 **이상 거래를 탐지하는 머신러닝 모델**을 개발하는 것을 목표로 합니다. 특히, 데이터 분석 및 모델링 과정에서 마주하는 **클래스 불균형**이라는 현실적인 문제를 체계적으로 해결하고, 이를 통해 문제 해결 역량을 강화하는 데 중점을 두었습니다.

---

### **2. 주요 분석 결론 및 인사이트**

* **클래스 불균형의 심각성**: 전체 거래 중 이상 거래는 0.17%에 불과한 심각한 불균형 상태를 확인했습니다. 이러한 불균형 데이터로는 모델이 이상 거래를 제대로 학습하지 못해, **정확도(Accuracy)**가 높더라도 실제 이상 거래를 놓치는 문제가 발생합니다.
* **유의미한 피처 패턴**: 이상 거래는 정상 거래와 달리 **특정 시간대(`Time`)와 금액대(`Amount`)**에 집중적으로 발생하는 패턴을 발견했습니다. 이러한 패턴은 모델이 이상 거래를 분류하는 중요한 단서가 됩니다.
* **모델 선택의 중요성**: 이상 거래 탐지에서는 **재현율(Recall)**을 극대화하는 것이 핵심 목표입니다. 이상 거래를 놓치는 것은 금융 손실로 직결되기 때문입니다. 모델 평가 결과, **로지스틱 회귀 모델**이 가장 높은 재현율을 기록하여 이 문제에 가장 적합한 모델로 선정되었습니다.

---

### **3. 프로젝트 단계별 과정**

#### **3.1. 1단계: 프로젝트 기획 및 데이터 수집**
프로젝트의 목표와 방향성을 설정하고, Kaggle의 [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) 데이터셋을 확보했습니다.

#### **3.2. 2단계: 데이터 탐색 및 전처리**
모델링을 위한 데이터 준비 과정을 수행했습니다.

* **피처 스케일링**: 모델이 특정 피처에 편향되지 않도록 `Time`과 `Amount` 피처에 **StandardScaler**를 적용해 스케일을 맞추었습니다.
* **클래스 불균형 해결: 샘플링 기법 선택**
    * **언더샘플링(Under-sampling)**: 다수 클래스의 데이터를 줄이는 방법으로, 학습 속도가 빠르지만 중요한 데이터 정보를 손실할 위험이 있습니다.
    * **오버샘플링(Over-sampling)**: 소수 클래스의 데이터를 늘리는 방법으로, 데이터 손실 없이 모델에 다양한 패턴을 학습시킬 수 있습니다.
    * **SMOTE(Synthetic Minority Over-sampling Technique)**: 이 프로젝트에서는 **SMOTE**를 선택했습니다. 이는 단순히 소수 클래스를 복제하는 것이 아니라, 주변 데이터를 기반으로 새로운 가상 데이터를 생성하여 과적합 위험을 줄이면서 모델 학습 능력을 향상시키는 데 효과적입니다.

* **훈련/테스트 데이터 분할**: 모델의 일반화 성능을 객관적으로 평가하기 위해 전체 데이터를 훈련 데이터와 테스트 데이터로 분할했습니다.

#### **3.3. 3단계: 모델링 및 성능 평가**
다양한 머신러닝 모델을 적용하고, 비즈니스 목표에 맞는 평가지표를 활용해 성능을 평가했습니다.

* **모델 선정**: **로지스틱 회귀**, **랜덤 포레스트**, **LightGBM**을 비교 분석했습니다. 이 모델들은 각각 선형 모델, 앙상블 모델, 부스팅 모델의 대표 주자로서 서로 다른 학습 방식의 장단점을 비교하는 데 유용했습니다.
* **평가 지표**: **혼동 행렬(Confusion Matrix)**, **정밀도(Precision)**, **재현율(Recall)**, **ROC-AUC**를 사용하여 모델의 성능을 다각도로 분석했습니다.

#### **3.4. 4단계: 최종 분석 및 시각화**
프로젝트의 모든 과정을 종합하고 핵심 분석 결과를 효과적으로 시각화했습니다.

* **ROC Curve 비교**: 각 모델의 **ROC Curve**를 한 그래프에 그려, 이상 거래와 정상 거래를 구별하는 능력을 직관적으로 비교했습니다. 이 시각화는 모델 선정의 중요한 근거가 되었습니다.
* **최종 결론**: **재현율**을 최우선 지표로 삼아 **로지스틱 회귀 모델**을 최종 모델로 선정했습니다. 이 과정을 통해 데이터 분석에서는 비즈니스 목표에 맞는 평가 지표를 선택하는 것이 가장 중요하다는 교훈을 얻었습니다.

---

### **4. 사용 기술 및 라이브러리**

* **Python**
* **Pandas**: 데이터 처리 및 분석
* **NumPy**: 수치 연산
* **Matplotlib, Seaborn**: 데이터 시각화
* **Scikit-learn, Imbalanced-learn**: 머신러닝 모델링 및 전처리
